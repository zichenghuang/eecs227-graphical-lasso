{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/michael/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # For sentiment analysis\n",
    "import cPickle as pickle # For loaded dataset from pickle file\n",
    "import tqdm # Progress bar\n",
    "from collections import Counter # Handy addon\n",
    "from pprint import pprint # Useful to print JSON objects\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset of articles with introductions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57767 articles were loaded\n",
      "Example article:\n",
      "{u'introductions': [{u'person': u'Bashar al-Assad',\n",
      "                     u'text': u'President',\n",
      "                     u'wdid': u'Q44329'},\n",
      "                    {u'person': u'Emile Hokayem',\n",
      "                     u'text': u'in Foreign Policy'},\n",
      "                    {u'person': u'Ahrar al Sham',\n",
      "                     u'text': u'the most important groups',\n",
      "                     u'wdid': u'Q860943'},\n",
      "                    {u'person': u'Vladimir Putin',\n",
      "                     u'text': u'Russian President',\n",
      "                     u'wdid': u'Q7747'},\n",
      "                    {u'person': u'Barack Obama',\n",
      "                     u'text': u'U.S. President',\n",
      "                     u'wdid': u'Q76'},\n",
      "                    {u'person': u'Osama Abu Zeid',\n",
      "                     u'text': u'a senior adviser to the moderate Free Syrian Army'},\n",
      "                    {u'person': u'Op-Ed',\n",
      "                     u'text': u'for The Washington Post',\n",
      "                     u'wdid': u'Q2602337'},\n",
      "                    {u'person': u'Nicholas Burns',\n",
      "                     u'text': u'two former senior officials',\n",
      "                     u'wdid': u'Q7025139'},\n",
      "                    {u'person': u'Natalie Nougayr\\xe8de',\n",
      "                     u'text': u'Guardian columnist',\n",
      "                     u'wdid': u'Q6430048'},\n",
      "                    {u'person': u'Natalie Nougayr\\xe8de',\n",
      "                     u'text': u'',\n",
      "                     u'wdid': u'Q6430048'}],\n",
      " 'news_topic': 'ISIS War',\n",
      " u'pubtime': datetime.datetime(2016, 2, 8, 15, 18, 6),\n",
      " u'source': u'cnn.com',\n",
      " u'title': u'Aleppo siege marks upheaval on Syrian battlefield',\n",
      " u'url': u'http://www.cnn.com/2016/02/07/middleeast/syria-aleppo-siege/index.html?eref=rss_world'}\n"
     ]
    }
   ],
   "source": [
    "# This loads the file that you want, might take several seconds (up to a minute)\n",
    "\n",
    "with open(\"news_sentiment.pickle\", \"r\") as f:\n",
    "    articles = pickle.load(f)\n",
    "print len(articles), \"articles were loaded\"\n",
    "print \"Example article:\"\n",
    "pprint(articles[1040])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39206  articles from ISIS War and  18561 articles from Brexit were loaded\n"
     ]
    }
   ],
   "source": [
    "# separate articles from the two stories\n",
    "ISIS_articles = []\n",
    "Brexit_articles = []\n",
    "for a in articles:\n",
    "    if a[\"news_topic\"] == 'ISIS War':\n",
    "        ISIS_articles.append(a)\n",
    "    else:\n",
    "        Brexit_articles.append(a)\n",
    "        \n",
    "print len(ISIS_articles), \" articles from ISIS War and \", len(Brexit_articles), \"articles from Brexit were loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get only articles from one story, you can change this\n",
    "articles = ISIS_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract introductions, and obtain their sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "total_introductions = []\n",
    "for a in articles:\n",
    "    for intro in a.get('introductions', []):\n",
    "        intro['source'] = a['source']\n",
    "        total_introductions.append(intro)\n",
    "\n",
    "for intro in tqdm.tqdm_notebook(total_introductions):\n",
    "    intro['sentiment'] = analyzer.polarity_scores(intro['text'])['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gets all of the introductions and splits on whitespace\n",
    "intro_texts = map(lambda x: x[u'text'].split(), total_introductions)\n",
    "# converts to lowercase and flattens list\n",
    "words = []\n",
    "for intro in intro_texts:\n",
    "    for word in intro:\n",
    "        words.append(word.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counts all of the words\n",
    "word_counts = {}\n",
    "for word in words:\n",
    "    # word already seen\n",
    "    if word in word_counts:\n",
    "        word_counts[word] += 1\n",
    "    else:\n",
    "        word_counts[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# most common words found\n",
    "word_counts_list = [el for el in word_counts.iteritems()]\n",
    "word_counts_list.sort(key = lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most common words\n",
      "the, 53207\n",
      "of, 30492\n",
      "president, 30058\n",
      "minister, 23643\n",
      "a, 22037\n",
      "'s, 20523\n",
      "in, 18812\n",
      "-, 17370\n",
      "prime, 12534\n",
      "who, 12132\n"
     ]
    }
   ],
   "source": [
    "# prints most common words\n",
    "n = 10\n",
    "print '%s most common words' % n\n",
    "for i in range(n):\n",
    "    print '%s, %s' % (word_counts_list[i][0], word_counts_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters for selecting important words\n",
    "word_pos_threshold = 0.1\n",
    "word_neg_threshold = -0.1\n",
    "word_freq_threshold = 100  # shows up at least this many times\n",
    "\n",
    "charged_words = []\n",
    "for word, count in word_counts_list:\n",
    "    if count < word_freq_threshold:\n",
    "        break  # ok because sorted by frequency already\n",
    "    word_sentiment = analyzer.polarity_scores(word)['compound']\n",
    "    if word_sentiment > word_pos_threshold or word_sentiment < word_neg_threshold:\n",
    "        charged_words.append((word, word_sentiment, count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "charged_words_list = zip(*charged_words)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example some sentiment for some of the introductions\n",
    "\n",
    "subsample = np.random.choice(total_introductions, 100)\n",
    "for intro in subsample:\n",
    "    if intro['sentiment'] != 0:\n",
    "        print \"---------------\"\n",
    "        print \"Entity mentionned:\", intro['person']\n",
    "        print intro['text']\n",
    "        print \"Sentiment:\", intro['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a 2-dimensional object containing sentiment per entity, per source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for indexing the charged words\n",
    "charged_words_dict = dict(zip(charged_words_list, [i for i in range(len(charged_words_list))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count number of unique sources\n",
    "sources = set(map(lambda intro: intro['source'], total_introductions))\n",
    "num_unique_sources = len(sources)\n",
    "sources_dict = dict(zip(list(sources), [i for i in range(len(sources))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build word count matrix that is sources by charged_words\n",
    "\n",
    "# initialize with zeros\n",
    "data_matrix_sources = np.zeros((len(charged_words_list), num_unique_sources), dtype=np.float)\n",
    "\n",
    "for intro in total_introductions:\n",
    "    intro_text = intro[u'text'].split()\n",
    "    \n",
    "    # if word is a charged word, increment corresponding data cell by 1\n",
    "    for word in intro_text:\n",
    "        if word in charged_words_dict:\n",
    "            s = intro['source']\n",
    "            data_matrix_sources[charged_words_dict[word], sources_dict[s]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count number of unique people\n",
    "people = set(map(lambda intro: intro['person'], total_introductions))\n",
    "num_unique_people = len(people)\n",
    "people_dict = dict(zip(list(people), [i for i in range(len(people))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build word count matrix that is people by charged_words\n",
    "\n",
    "# initialize with zeros\n",
    "data_matrix_people = np.zeros((len(charged_words_list), num_unique_people), dtype=np.float)\n",
    "\n",
    "for intro in total_introductions:\n",
    "    intro_text = intro[u'text'].split()\n",
    "    \n",
    "    # if word is a charged word, increment corresponding data cell by 1\n",
    "    for word in intro_text:\n",
    "        if word in charged_words_dict:\n",
    "            p = intro['person']\n",
    "            data_matrix_people[charged_words_dict[word], people_dict[p]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count number of unique people\n",
    "source_people = set(map(lambda intro: (intro['source'], intro['person']), total_introductions))\n",
    "num_unique_source_people = len(source_people)\n",
    "source_people_dict = dict(zip(list(source_people), [i for i in range(len(source_people))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build word count matrix that is (source, people) by charged_words\n",
    "\n",
    "# initialize with zeros\n",
    "data_matrix_people = np.zeros((len(charged_words_list), num_unique_source_people), dtype=np.float)\n",
    "\n",
    "for intro in total_introductions:\n",
    "    intro_text = intro[u'text'].split()\n",
    "    \n",
    "    # if word is a charged word, increment corresponding data cell by 1\n",
    "    for word in intro_text:\n",
    "        if word in charged_words_dict:\n",
    "            s = intro['source']\n",
    "            p = intro['person']\n",
    "            data_matrix_people[charged_words_dict[word], source_people_dict[(s, p)]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ent_source_sent = {}\n",
    "\n",
    "for intro in total_introductions:\n",
    "    p = intro['person']\n",
    "    s = intro['source']\n",
    "    if p not in ent_source_sent:\n",
    "        ent_source_sent[p] = {}\n",
    "    if s not in ent_source_sent[p]:\n",
    "        ent_source_sent[p][s] = []\n",
    "    ent_source_sent[p][s].append(intro['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'nytimes.com': [0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.5574, 0.0, 0.0, 0.0, 0.0], u'allafrica.com': [-0.5994], u'bloomberg.com': [-0.5994, 0.0, 0.0, -0.2023, 0.0, -0.4404, -0.1531, -0.1531, 0.0, 0.0], u'bbc.co.uk': [0.0516, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, -0.3182, -0.5994, -0.5994, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0], u'theguardian.com': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.7096, 0.0, -0.1531, 0.0], u'telegraph.co.uk': [0.4019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3182, 0.4404, -0.296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818, -0.1531, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.3182, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3612, 0.2023, -0.1531, 0.0, 0.0, -0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], u'independent.co.uk': [-0.1531, 0.0, -0.0258, -0.1531, -0.6597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1779, 0.0, 0.0, -0.2023, 0.0, -0.2023, 0.0, -0.2023, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, 0.0, -0.2023, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, -0.2023, -0.2023, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], u'washingtonpost.com': [0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, -0.5859], u'foxnews.com': [0.0, 0.5709, -0.5994, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, -0.1531, 0.0, -0.1531, 0.0, -0.5994, 0.0, 0.0, -0.1531, -0.6249, 0.0, -0.6249, 0.0, -0.6249, -0.5574, -0.8402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.2732, 0.0, -0.4939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0], u'aa.com.tr': [0.0, -0.5994, -0.4019, 0.0, 0.0, 0.0, -0.5994, 0.0, -0.5994, 0.0, 0.0, 0.4588, -0.5994, 0.0, 0.0, 0.0, -0.7184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], u'rt.com': [0.5574, 0.5574, 0.0, 0.0, 0.0, -0.5994, 0.0, -0.5994, -0.5994, 0.0, 0.0, 0.0, 0.0, -0.8316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6908], u'france24.com': [-0.3182, 0.0, -0.6705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, -0.5023, 0.0, 0.0, 0.0, -0.1531, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.743, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.4767, -0.5994, -0.9136, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5106, -0.6808, -0.3818, 0.0, 0.0, 0.0, 0.0, 0.3182, 0.4404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.8176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, -0.6249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5023, 0.0, 0.0, 0.5023, 0.0258, 0.0258, 0.0, -0.1531, -0.1531, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1779, -0.1531, 0.0, -0.4019, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, -0.1531, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, -0.3818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.0, 0.0], u'latimes.com': [0.0, 0.0], u'cnn.com': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0516, 0.0, 0.0, 0.0, -0.5994, -0.3818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.7096, -0.7096, 0.0, 0.0, 0.0, -0.3612, 0.0, 0.0, 0.0, 0.0, 0.0, -0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1779], u'reuters.com': [-0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, -0.5994, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3612, -0.3612, 0.0, 0.0, 0.0, 0.0, -0.5106, 0.0, 0.0, 0.0, -0.3818, 0.0, 0.3182, 0.4404, 0.0, 0.3182, 0.4404, 0.0, -0.4404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.3182, -0.3182, -0.5994, 0.0, -0.4588, 0.0, 0.0, -0.6808, 0.0, -0.4767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4404, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6124, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1779, 0.0, -0.1779, -0.1531, -0.5994, -0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.128, 0.0, 0.0, 0.0], u'chinadaily.com.cn': [0.0, 0.0], u'middleeasteye.net': [-0.1531, 0.0, 0.0, 0.0, 0.0, -0.1531, -0.4404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3612, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.2023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], u'aljazeera.com': [-0.3182, 0.0, 0.0, -0.1531, 0.0, 0.0, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, -0.1531, 0.0, 0.0, 0.0, 0.0, 0.0, -0.1531, 0.0, -0.34, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0516, -0.0516, -0.1531, 0.0, 0.0, -0.4404, -0.4404], u'ap.org': [0.0, -0.1531, 0.0, 0.0, 0.0, -0.5994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5709, 0.0, 0.0, 0.0, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "# An example of how one entity (a city) is described by different sources\n",
    "\n",
    "print ent_source_sent['Aleppo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will keep a total of 7852 / 25128 in our dataset\n",
      "We have  22 sources:  [u'telegraph.co.uk', u'foxnews.com', u'ap.org', u'businessinsider.in', u'independent.co.uk', u'reuters.com', u'wikinews.org', u'cnn.com', u'techcrunch.com', u'aa.com.tr', u'allafrica.com', u'nytimes.com', u'bloomberg.com', u'bbc.co.uk', u'latimes.com', u'rt.com', u'france24.com', u'chinadaily.com.cn', u'theguardian.com', u'washingtonpost.com', u'middleeasteye.net', u'aljazeera.com']\n"
     ]
    }
   ],
   "source": [
    "# We get rid of entities that don't contain enough data\n",
    "\n",
    "entities_kept = []\n",
    "\n",
    "for entity in ent_source_sent.keys():\n",
    "    sentiments = ent_source_sent[entity]\n",
    "    total_size = sum([len(sentiments[source]) for source in sentiments.keys()])\n",
    "    if total_size >= 3:\n",
    "        entities_kept.append(entity)\n",
    "        \n",
    "print \"We will keep a total of %s / %s in our dataset\" % (len(entities_kept), len(ent_source_sent.keys()))\n",
    "\n",
    "\n",
    "sources = set([])\n",
    "for entity in entities_kept:\n",
    "    sources|= set(ent_source_sent[entity].keys())\n",
    "sources = list(sources)\n",
    "\n",
    "print \"We have \", len(sources), \"sources: \", sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create the array we will use in our sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We allocated some sentiment in this matrix, the repartition is: Counter({0: 19061, 1: 3650, -1: 2670})\n"
     ]
    }
   ],
   "source": [
    "# Parameters: changing these affects the results you get\n",
    "Pos_neg_ratio = 2.0\n",
    "overall_ratio = 0.15\n",
    "pos_threshold = 0.15\n",
    "neg_threshold = -0.15\n",
    "\n",
    "N = len(entities_kept)\n",
    "M = len(sources)\n",
    "A = np.zeros((N, M))\n",
    "\n",
    "sentiment_counts = Counter()\n",
    "\n",
    "source2j = {source: j for j, source in enumerate(sources)}\n",
    "\n",
    "for i, entity in enumerate(entities_kept):\n",
    "    for source in ent_source_sent[entity].keys():\n",
    "        sent_array = np.array(ent_source_sent[entity][source])\n",
    "        N_pos = float(len(np.where(sent_array > pos_threshold)[0]))\n",
    "        N_neg = float(len(np.where(sent_array < neg_threshold)[0]))\n",
    "        T = float(len(sent_array))\n",
    "        aggregate_sentiment = 0\n",
    "        if N_pos > Pos_neg_ratio*N_neg and N_pos > overall_ratio*T:\n",
    "            aggregate_sentiment = 1\n",
    "        elif N_neg > Pos_neg_ratio*N_pos and N_neg > overall_ratio*T:\n",
    "            aggregate_sentiment = -1\n",
    "        j = source2j[source]\n",
    "        \n",
    "        A[i,j] = aggregate_sentiment\n",
    "        \n",
    "        sentiment_counts[aggregate_sentiment] += 1\n",
    "\n",
    "print \"We allocated some sentiment in this matrix, the repartition is:\", sentiment_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model source similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 22)\n",
      "(4, 22)\n",
      "[[ -2.57161676e+02  -3.13124873e+01  -1.67514264e-01  -1.56728158e+02\n",
      "   -7.57601502e+01  -2.88576253e+01  -4.47549446e+02  -4.75839309e+00\n",
      "   -6.99757120e+02  -2.04463264e+02  -8.41720300e+01  -7.08626227e+01\n",
      "   -2.02961059e+02  -8.23089470e+01  -5.92573446e+00  -2.02288184e+02\n",
      "   -3.00643126e-01  -1.05936915e+00  -2.35632614e+02  -3.90852246e+01\n",
      "   -1.03738181e+01  -7.10581633e+01]\n",
      " [  4.93739773e+01  -2.05719125e+00  -2.40631681e-01   7.01256579e+01\n",
      "    3.25005574e+01   2.77506829e+00  -5.98477771e+01   1.22349241e+00\n",
      "   -9.60657517e+01   7.72828526e+01  -2.62763204e+01   6.73159658e+00\n",
      "    6.95906502e+00   2.35199193e+01   2.41944409e+00   1.14241671e+02\n",
      "   -1.15557934e-01   2.83374284e-01   8.45980602e+01   3.12673349e-02\n",
      "    7.24848682e+00   1.27662484e+01]\n",
      " [  1.52291873e+00   3.32105358e+00   4.80592117e-02  -3.28681992e+01\n",
      "   -8.21196740e+01  -6.57151721e+00   4.53062675e+01   8.48634493e-01\n",
      "   -5.07702394e+01  -7.27273414e+00   7.18504147e+00   2.10535145e+01\n",
      "    8.56409735e+01   2.17255941e+01  -3.40133316e+00   1.91037532e+01\n",
      "   -3.49197265e-01  -7.62012101e-01  -1.05494354e+00   1.51322808e+01\n",
      "    5.92505760e-01   1.45114374e+01]\n",
      " [ -1.13891880e+01  -1.07893937e+00   1.05290602e-01   2.23998455e+01\n",
      "    9.93547062e+01   8.47198597e+00   4.74176820e+01  -1.45518558e-01\n",
      "   -3.75314967e+01  -1.63003733e+01   1.57929002e+01   2.61322932e+01\n",
      "    3.85705511e+01  -1.19010332e+01   1.56165684e+00  -8.35332067e+00\n",
      "    2.81589199e-01   4.46134362e-01  -1.72850897e+01   6.10598746e+00\n",
      "   -8.22916465e-01   7.33289959e+00]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True]\n",
      " [False  True  True False False False  True False  True False  True False\n",
      "  False False False False  True False False False False False]\n",
      " [False False False  True  True  True False False  True  True False False\n",
      "  False False  True False  True  True  True False False False]\n",
      " [ True  True False False False False False  True  True  True False False\n",
      "  False  True False  True False False  True False  True False]]\n",
      "--Return--\n",
      "> <ipython-input-108-699950f65d0e>(21)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-699950f65d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  Sparse PCA stuff\n",
    "#  want to find what journals think of people overall.\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "test_data = np.zeros((22, 22))\n",
    "test_data[0, 0] = 100\n",
    "\n",
    "n = 4 # extract 5 components\n",
    "# alpha is a sparsity param\n",
    "print data_matrix_sources.shape\n",
    "estimator = decomposition.SparsePCA(n_components=n, alpha=1e-2)\n",
    "#estimator.fit_transform(data_matrix_sources)  # for reduction on sources\n",
    "estimator.fit_transform(data_matrix_sources)  # for reduction on words\n",
    "\n",
    "components = estimator.components_\n",
    "projected_data = estimator.fit_transform(data_matrix_sources)\n",
    "print components.shape\n",
    "#import pdb; pdb.set_trace()\n",
    "print(components)\n",
    "print(components <= 0)\n",
    "\n",
    "import pdb; pdb.set_trace()\n",
    "x=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write code that uses this matrix (entities, sources) to compute\n",
    "# source similarity visible in bias of the way they describe entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def soft_threshold (x, t):\n",
    "    if x > 0:\n",
    "        return max(x-t, 0)\n",
    "    else:\n",
    "        return min(x+t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graphical_lasso(X, lambda_initial_guess = 1e-2, lambda_lasso = 1e-2\n",
    "                    max_iteration_matrix=10, max_iteration_partition=10,\n",
    "                    convergence_threshold_matrix = 1e-2, convergence_threshold_partition=1e-6):\n",
    "    S = np.cov(X.T)  # sampled covariance S\n",
    "    if lambda_lass == 0:\n",
    "        return np.linalg.inv(S)\n",
    "    \n",
    "    p = S.shape[0]\n",
    "    W = S + lambda_initial_guess * np.identity(p)\n",
    "    precision = np.linalg.inv(W)\n",
    "    index = np.arange(p)  # for ease of indexing later\n",
    "    \n",
    "    for i in range(max_iteration_matrix):\n",
    "        beta_coefs = np.zeros((p-1, p), dtype=np.float)\n",
    "        for j in range(p):\n",
    "            # partition W and S\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graphical_lasso (X, lambda_parameter = 0.01, max_iteration = 10, threshold = 0.01):\n",
    "    # X: the original data matrix\n",
    "    # lambda_parameter: hyperparameter for L1 penalty\n",
    "    # max_iteration: maximum iteration\n",
    "    # threshold: convergence threshold\n",
    "    \n",
    "    # check if hyperparameter is zero\n",
    "    if lambda_parameter == 0:  # when lambda = 0, simply reutrn the inverse of sample covariance matrix\n",
    "        return np.linalg.inv(np.cov(X.T))\n",
    "    \n",
    "    # if hyperparameter is not zero, go on to do the following\n",
    "    # step 1 in algorithm 9.1\n",
    "    p = X.shape[1]                          # number of features\n",
    "    S = np.cov(X.T)                         # sample covariance matrix\n",
    "    W = np.cov(X.T)                         # set the initial W matrix\n",
    "    precision = np.linalg.inv(np.cov(X.T))  # initialize the precision matrix\n",
    "    index = np.arange(p)                    # index used to partition the matrix W and S\n",
    "    \n",
    "    # step 2 in algorithm 9.1\n",
    "    for i in range(max_iteration):\n",
    "        #W_old = W  # later used to check for convergence\n",
    "        B = np.zeros((p - 1, p))                  # used to store the beta coefficients\n",
    "\n",
    "        for j in range(p):\n",
    "            \n",
    "            # partition W and S\n",
    "            W_11 = W[index != j].T[index != j]        # select W matrix's all but the jth row and column to form W_11\n",
    "            s_12 = S[j, index != j]                   # select the s12 from S, I actually select s12.T for easier dimension\n",
    "            beta_j = - precision[index != j, j] / precision[j, j]  ##??## is this the right way to define the initial beta_j?\n",
    "            V = W[index != j].T[index != j]           # used in coordinate descent\n",
    "            \n",
    "            # pathwise coordinate descent\n",
    "            for n in range(max_iteration):\n",
    "                #beta_old = beta_j.copy()  # previous beta, used for checking convergence of beta_j\n",
    "                for k in range(p - 1): \n",
    "                    ##!!## this is adopted from 17.26 in Elements of Statistical Learning by Hastie, Tishirani, and Friedman\n",
    "                    beta_j[k] = soft_threshold(s_12[k] - np.dot(V[np.arange(p - 1) != j, k], beta_j[np.arange(p - 1) != j]), \n",
    "                                               lambda_parameter) / V[k, k]\n",
    "                    \n",
    "                #if np.abs(beta_j - beta_old).mean() < threshold: ####!!#### some better test for convergence of beta_j\n",
    "                #    B[np.arange(p - 1), j] = beta_j\n",
    "                #    break\n",
    "            \n",
    "            # store the beta coefficients for jth freature\n",
    "            B[np.arange(p - 1), j] = beta_j\n",
    "            \n",
    "            #else:\n",
    "            #    # this triggers if break command did not occur\n",
    "            #    print \"The coordinate descent did not converge. Try to increase the maximum number of iterations.\"\n",
    "                \n",
    "            # update the w_12\n",
    "            W[index != j, j] = np.dot(W_11, beta_j)\n",
    "            \n",
    "        #if check_convergence(W_old, W, S, threshold):\n",
    "        #    break\n",
    "            \n",
    "    #else:\n",
    "    #    # this triggers if break command did not occur\n",
    "    #    print \"The algorithm did not converge. Try to increase the maximum number of iterations.\"\n",
    "    \n",
    "    # update the precision matrix\n",
    "    # step 3 in algorithm 9.1\n",
    "    for j in range(p):\n",
    "        precision[j, j] = 1 / (W[j, j] - np.dot(W[index != j, j], B[np.arange(p - 1), j]))  # this is theta_hat_22\n",
    "        precision[index != j, j] = - B[np.arange(p - 1), j] * precision[j, j]               # this is theta_hat_12\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = graphical_lasso(A, lambda_parameter=1e-2) # try it with the A matrix specified in Sentiment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.4984276574\n",
      "0.234252614242\n",
      "--Return--\n",
      "> <ipython-input-26-0748940d0e2e>(7)<module>()->None\n",
      "-> import pdb; pdb.set_trace()\n",
      "(Pdb) result == result.T\n",
      "array([[ True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [False,  True,  True,  True,  True, False,  True, False,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True, False,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [False, False,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True, False, False,  True,  True,  True, False,  True,\n",
      "         True, False,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [False, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True, False,  True,  True,  True, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True]], dtype=bool)\n",
      "(Pdb) result - result.T\n",
      "array([[ 0.        , -0.00651263,  0.        ,  0.        ,  0.        ,\n",
      "        -0.02284489,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        , -0.34400431,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.00651263,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        -0.01324009,  0.        , -0.00075948,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        , -0.32411266,  0.        ,  0.        , -0.03725106,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.02284489,  0.01324009,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.03864629,  0.        ,  0.        ,\n",
      "         0.        ,  0.02259443,  0.00579221,  0.        ,  0.        ,\n",
      "         0.        ,  0.1189328 ,  0.        ,  0.        , -0.00639827,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.00075948,  0.        ,  0.        ,  0.        ,\n",
      "        -0.03864629,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        -0.02259443,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        -0.00579221,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.34400431,  0.32411266,  0.        ,  0.        ,  0.        ,\n",
      "        -0.1189328 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        -0.01811558,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.03725106,  0.        ,  0.        ,  0.        ,\n",
      "         0.00639827,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.01811558,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ]])\n",
      "(Pdb) np.linalg.norm(result)\n",
      "8832.1953951858904\n",
      "(Pdb) np.linalg.norm(result - result.T)\n",
      "0.69579813139875302\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0748940d0e2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_inv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'return'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_return\u001b[0;34m(self, frame, arg)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_returning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "\n",
    "result_inv = np.linalg.inv(result)\n",
    "print np.linalg.norm(A)\n",
    "print np.linalg.norm(result_inv)\n",
    "\n",
    "import pdb; pdb.set_trace()\n",
    "\n",
    "x = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {
    "778194441efa4fe0ac005b5453b5c790": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
